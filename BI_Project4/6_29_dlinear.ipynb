{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이동평균계산\n",
    "class moving_avg(nn.Module):\n",
    "    \"\"\"\n",
    "    Moving average block to highlight the trend of time series\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size, stride):\n",
    "        super(moving_avg, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.avg = nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=0)\n",
    "#AvgPoolid 이동평균계산하기 양끝을 패딩함\n",
    "    def forward(self, x):\n",
    "        # padding on the both ends of time series\n",
    "        front = x[:, 0:1, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        end = x[:, -1:, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        x = torch.cat([front, x, end], dim=1)\n",
    "        x = self.avg(x.permute(0, 2, 1))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시계열 분해하기 이동펴ㅕㅇ균(트랜드계산하고 시계열 데이터에 빼서 계절성 추출 \n",
    "class series_decomp(nn.Module):\n",
    "    \"\"\"\n",
    "    Series decomposition block\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size):\n",
    "        super(series_decomp, self).__init__()\n",
    "        self.moving_avg = moving_avg(kernel_size, stride=1) #이동평균계산\n",
    "\n",
    "    def forward(self, x):\n",
    "        moving_mean = self.moving_avg(x)\n",
    "        res = x - moving_mean\n",
    "        return res, moving_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#사용자 정의 모듈 주요 클래스 \n",
    "# 트랜드와 계절성에 대한 복잡한 패턴을 학습 \n",
    "# 트랜드와 계절성 분리하고 각가에 대한 예측을 수행 \n",
    "class Model(nn.Module):\n",
    "    \"\"\"\n",
    "    DLinear\n",
    "    \"\"\"\n",
    "    def __init__(self, configs):\n",
    "        super(Model, self).__init__()\n",
    "        self.Lag  = configs.Lag\n",
    "        self.Horizon = configs.Horizon\n",
    "\n",
    "        # Decompsition Kernel Size\n",
    "        kernel_size       = configs.kernel_size\n",
    "        self.decompsition = series_decomp(kernel_size)\n",
    "        self.individual   = configs.individual\n",
    "        self.channels     = configs.enc_in\n",
    "\n",
    "        if self.individual:\n",
    "            self.Linear_Seasonal = nn.ModuleList()\n",
    "            self.Linear_Trend    = nn.ModuleList()\n",
    "            self.Linear_Decoder  = nn.ModuleList()\n",
    "            for i in range(self.channels):\n",
    "                self.Linear_Seasonal.append(nn.Linear(self.Lag,self.Horizon))\n",
    "                self.Linear_Seasonal[i].weight = nn.Parameter((1/self.Lag)*torch.ones([self.Horizon,self.Lag]))\n",
    "                self.Linear_Trend.append(nn.Linear(self.Lag,self.Horizon))\n",
    "                self.Linear_Trend[i].weight = nn.Parameter((1/self.Lag)*torch.ones([self.Horizon,self.Lag]))\n",
    "                self.Linear_Decoder.append(nn.Linear(self.Lag,self.Horizon))\n",
    "        else:\n",
    "            self.Linear_Seasonal = nn.Linear(self.Lag,self.Horizon)\n",
    "            self.Linear_Trend = nn.Linear(self.Lag,self.Horizon)\n",
    "            self.Linear_Decoder = nn.Linear(self.Lag,self.Horizon)\n",
    "            self.Linear_Seasonal.weight = nn.Parameter((1/self.Lag)*torch.ones([self.Horizon,self.Lag]))\n",
    "            self.Linear_Trend.weight = nn.Parameter((1/self.Lag)*torch.ones([self.Horizon,self.Lag]))\n",
    "#forward는 모델이 입력 뎅디터를 받아 결과를 출력하는 방법임 각각(트랜드 계절성) 에 대해 선형변환을 적용후 다시 합치는 과정 \n",
    "    def forward(self, x):\n",
    "        # x: [Batch, Input length, Channel]\n",
    "        seasonal_init, trend_init = self.decompsition(x)\n",
    "        seasonal_init, trend_init = seasonal_init.permute(0,2,1), trend_init.permute(0,2,1)\n",
    "        if self.individual:\n",
    "            seasonal_output = torch.zeros([seasonal_init.size(0),seasonal_init.size(1),self.Horizon],dtype=seasonal_init.dtype).to(seasonal_init.device)\n",
    "            trend_output = torch.zeros([trend_init.size(0),trend_init.size(1),self.Horizon],dtype=trend_init.dtype).to(trend_init.device)\n",
    "            for i in range(self.channels):\n",
    "                seasonal_output[:,i,:] = self.Linear_Seasonal[i](seasonal_init[:,i,:])\n",
    "                trend_output[:,i,:] = self.Linear_Trend[i](trend_init[:,i,:])\n",
    "        else:\n",
    "            seasonal_output = self.Linear_Seasonal(seasonal_init)\n",
    "            trend_output = self.Linear_Trend(trend_init)\n",
    "\n",
    "        x = seasonal_output + trend_output\n",
    "        return x.permute(0,2,1) # to [Batch, Output length, Channel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 준비\n",
    "data = pd.read_csv('6_20.csv') # 파일명은 실제 데이터 파일 경로로 수정\n",
    "data = data[['공급능력(MW)', '현재수요(MW)', '공급예비력(MW)', '공급예비율(퍼센트)', '운영예비력(MW)', '운영예비율(퍼센트)', '요일', 'is_holiday_or_weekend', '요일1', '요일2', '요일3']]\n",
    "data = torch.Tensor(np.array(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1135579"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.Lag = 105120 # 1년 데이터 (5분 간격)\n",
    "        self.Horizon = 72 # 6시간 데이터 (5분 간격)\n",
    "        self.kernel_size = 3 # kernel size for moving average\n",
    "        self.individual = False # individual linear for each channel\n",
    "        self.enc_in = data.size(-1) # number of channels\n",
    "\n",
    "configs = Config()\n",
    "\n",
    "def create_sequences(input_data, target_data, lag, horizon):\n",
    "    input_seq = []\n",
    "    target_seq = []\n",
    "\n",
    "    L = len(input_data)\n",
    "    for i in range(L - lag - horizon + 1):\n",
    "        input_seq.append(input_data[i:i+lag].tolist())\n",
    "        target_seq.append(target_data[i+lag:i+lag+horizon].tolist())\n",
    "\n",
    "    return torch.tensor(input_seq), torch.tensor(target_seq)\n",
    "\n",
    "\n",
    "input_data = data[:-configs.Horizon] # 입력 데이터\n",
    "target_data = data[configs.Lag:] # 예측 대상 데이터\n",
    "\n",
    "input_data, target_data = create_sequences(input_data, target_data, configs.Lag, configs.Horizon)\n",
    "\n",
    "dataset = TensorDataset(input_data, target_data)\n",
    "train_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=42) \n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "# 모델 초기화\n",
    "model = Model(configs)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 모델 학습\n",
    "for epoch in range(100): \n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_dataloader):\n",
    "        prediction = model(data)\n",
    "        loss = F.mse_loss(prediction, target) #\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # 역전파 및 가중치 업데이트\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= len(train_dataloader)\n",
    "    print('Train Epoch: {}, Avg. Loss: {}'.format(epoch, train_loss))\n",
    "\n",
    "  \n",
    "    if epoch % 10 == 0:\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(test_dataloader):\n",
    "                prediction = model(data)\n",
    "                loss = F.mse_loss(prediction, target) \n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(test_dataloader)\n",
    "        print('Validation Epoch: {}, Avg. Loss: {}'.format(epoch, val_loss))\n",
    "\n",
    "        # Visualizing model prediction\n",
    "        sample_data = next(iter(test_dataloader))[0][0] \n",
    "        model_output = model(sample_data.unsqueeze(0)) \n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.plot(sample_data.numpy(), label='Input')\n",
    "        plt.plot(range(configs.Lag, configs.Lag + configs.Horizon), model_output[0].detach().numpy(), label='Prediction')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Configurations\n",
    "# class Config:\n",
    "#     def __init__(self):\n",
    "#         self.Lag = 105120 # 1년 데이터 (5분 간격)\n",
    "#         self.Horizon = 72 # 6시간 데이터 (5분 간격)\n",
    "#         self.kernel_size = 3 # kernel size for moving average\n",
    "#         self.individual = False # individual linear for each channel\n",
    "#         self.enc_in = data.size(-1) # number of channels\n",
    "\n",
    "# configs = Config()\n",
    "\n",
    "# def create_sequences(input_data, target_data, lag, horizon):\n",
    "#     input_seq = []\n",
    "#     target_seq = []\n",
    "\n",
    "#     L = len(input_data)\n",
    "#     for i in range(L - lag - horizon + 1):\n",
    "#         input_seq.append(input_data[i:i+lag].tolist())\n",
    "#         target_seq.append(target_data[i+lag:i+lag+horizon].tolist())\n",
    "\n",
    "#     return torch.tensor(input_seq), torch.tensor(target_seq)\n",
    "\n",
    "\n",
    "# input_data = data[:-configs.Horizon] # 입력 데이터\n",
    "# target_data = data[configs.Lag:] # 예측 대상 데이터\n",
    "\n",
    "# input_data, target_data = create_sequences(input_data, target_data, configs.Lag, configs.Horizon)\n",
    "\n",
    "# dataset = TensorDataset(input_data, target_data)\n",
    "# train_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=42) # 80:20으로 train-test 데이터 분할\n",
    "\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "# # 모델 초기화\n",
    "# model = Model(configs)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # 모델 학습\n",
    "# for epoch in range(100): # 100 epochs\n",
    "#     train_loss = 0\n",
    "#     for batch_idx, (data, target) in enumerate(train_dataloader):\n",
    "#         prediction = model(data)\n",
    "#         loss = F.mse_loss(prediction, target) # Mean Squared Error loss\n",
    "#         train_loss += loss.item()\n",
    "\n",
    "#         # 역전파 및 가중치 업데이트\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#     train_loss /= len(train_dataloader)\n",
    "#     print('Train Epoch: {}, Avg. Loss: {}'.format(epoch, train_loss))\n",
    "   \n",
    "\n",
    "#     # Validate and print loss every 10 epochs\n",
    "#     if epoch % 10 == 0:\n",
    "#         model.eval()\n",
    "#         val_loss = 0\n",
    "#         with torch.no_grad():\n",
    "#             for batch_idx, (data, target) in enumerate(test_dataloader):\n",
    "#                 prediction = model(data)\n",
    "#                 loss = F.mse_loss(prediction, target) # Mean Squared Error loss\n",
    "#                 val_loss += loss.item()\n",
    "\n",
    "#         val_loss /= len(test_dataloader)\n",
    "#         print('Validation Epoch: {}, Avg. Loss: {}'.format(epoch, val_loss))\n",
    "\n",
    "#         # Visualizing model prediction\n",
    "#         sample_data = next(iter(test_dataloader))[0][0] # get a sample data from test dataloader\n",
    "#         model_output = model(sample_data.unsqueeze(0)) # get model output\n",
    "#         plt.figure(figsize=(12, 4))\n",
    "#         plt.plot(sample_data.numpy(), label='Input')\n",
    "#         plt.plot(range(configs.Lag, configs.Lag + configs.Horizon), model_output[0].detach().numpy(), label='Prediction')\n",
    "#         plt.legend()\n",
    "#         plt.show()\n",
    "\n",
    "#         model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train Epoch: {}, Avg. Loss: {}'.format(epoch, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
